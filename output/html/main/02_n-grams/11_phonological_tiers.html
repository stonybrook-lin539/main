<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>mathcommands-preproc</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="/main/style.css" />
  <!-- Include this in HTML headers to configure and activate MathJax. -->
  <script>
  MathJax = {
      loader: {
          load: ['a11y/assistive-mml']
      }
      options: {
          menuOptions: {
              settings: {
                  assistiveMml: true,   // true to enable assitive MathML
              }
          }
      }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"></script>
</head>
<body>
<div class="container with-sidebar">
<div class="sidenav">
<nav id="TOC" role="doc-toc">
<p><a id="site-title" href="/main">Mathematical Methods in Linguistics</a></p>
<ul>
<li><a href="#stop-word-removal-phonological-tiers">Stop word removal ~
phonological tiers</a>
<ul>
<li><a href="#the-limits-of-n-gram-grammars">The limits of <span
class="math inline">\(n\)</span>-gram grammars</a></li>
<li><a
href="#phonological-tiers-allow-for-smaller-grammars">Phonological tiers
allow for smaller grammars</a></li>
<li><a href="#the-mathematics-of-tiers">The mathematics of
tiers</a></li>
<li><a href="#recap">Recap</a></li>
</ul></li>
</ul>
</nav>
</div>
<div class="content">
<h1 id="stop-word-removal-phonological-tiers">Stop word removal ~
phonological tiers</h1>
<p>We started out this unit with <span
class="math inline">\(n\)</span>-gram grammars as a basic model for
studying the linguistic domains of phonotactics and morphotactics,
i.e. the rules that govern the arrangement of sounds and parts of word
like <em>un-</em>, <em>re-</em>, <em>-ly</em>, <em>-ize</em>,
<em>-ation</em>, <em>-s</em>, and so on. After that, we switched to more
applied issues and the bag-of-words model. In order to be truly
effective, the bag-of-words model must be combined with stop word
removal. You might think that stop word removal, being a technique for
real-world applications, offers nothing of value to linguistics. But
stop word removal is actually closely related to what linguists call
<em>phonological tiers</em>.</p>
<h2 id="the-limits-of-n-gram-grammars">The limits of <span
class="math inline">\(n\)</span>-gram grammars</h2>
<p>We already know that (positive/negative) <span
class="math inline">\(n\)</span>-gram grammars can be used to describe
all kinds of conditions on natural language phonotactics and
morphotactics. But these grammars can only enforce locally bounded
conditions like intervocalic voicing or penultimate stress. These
phenomena have the property that it suffices to consider a finitely
bounded number of adjacent segments. Not all natural language phenomena
obey this condition.</p>
<div class="example">
<p>One of these phenomena is attested in <strong>Samala</strong>, which
belongs to the group of Chumash languages spoken in southern California.
Samala displays a constraint known as <strong>long-distance sibilant
harmony</strong>. All sibilants in a word must agree in anteriority, no
matter how far apart they are. This means that a word can certainly
contain multiple instances of <em>s</em> or multiple instances of
<em>ʃ</em> (ʃ is the IPA symbol corresponding to English <em>sh</em>).
But it may never contain a mixture of the two. So <em>haʃxintilawaʃ</em>
is well-formed, whereas <em>hasxintilawaʃ</em> and
<em>haʃxinitilawas</em> are both ill-formed. The form
<em>hasxintilawas</em>, while not an actual word of Samala, would also
obey the sibilant harmony constraint.</p>
<p>Even a 10-gram grammar cannot capture these contrasts. A negative
10-gram grammar that generates both <em>hasxinitilawas</em> and
<em>haʃxintilawaʃ</em> must not forbid any of the following:</p>
<ul>
<li><em>sxintilawa</em></li>
<li><em>xintilawas</em></li>
<li><em>ʃxintilawa</em></li>
<li><em>xintilawaʃ</em></li>
</ul>
<p>But then this grammar would also allow for the illicit
<em>hasxintilawaʃ</em> and <em>haʃxintilawas</em>. Only an 11-gram
grammar could capture the contrast.</p>
</div>
<div class="exercise">
<p>Write an 11-gram grammar that generates <em>hasxintilawas</em> and
<em>haʃxintilawaʃ</em>, but not <em>hasxintilawaʃ</em> and
<em>haʃxinitilawas</em>. The grammar may be positive or negative,
whichever you prefer.</p>
</div>
<div class="exercise">
<p>Extend the grammar so that it also captures the fact that
<em>ʃtajanowonowaʃ</em> is licit whereas <em>stajanowonowaʃ</em> is
illicit. You might have to move beyond 11-grams.</p>
</div>
<p>Samala’s long-distance sibilant harmony can be handled by an <span
class="math inline">\(n\)</span>-gram grammar only if there is some
upper bound <span class="math inline">\(k &lt; n\)</span> such that
sibilants in a Samala word are never separated by more than <span
class="math inline">\(k\)</span> symbols. The examples above show that
this <span class="math inline">\(k\)</span> is at least 12, so one would
need at least a 13-gram grammar to handle the process. Such large <span
class="math inline">\(n\)</span>-grams simply aren’t feasible in
practice.</p>
<div class="example">
<p>Suppose for the sake of argument that Samala has only three sounds: a
vowel, <em>s</em>, and <em>ʃ</em>. Then there are <span
class="math inline">\(3^{13} = 1,594,323\)</span> distinct <span
class="math inline">\(n\)</span>-grams. Only the <span
class="math inline">\(n\)</span>-grams that do not mix <em>s</em> and
<em>ʃ</em> are well-formed, of which there are <span
class="math inline">\(2 \times 2^{13} = 2^{14} = 16,384\)</span>. So a
positive 13-gram grammar for Samala’s sibilant harmony would contain
<span class="math inline">\(16,384\)</span> distinct 13-grams (plus a
few with ⋊ or ⋉), and a negative one <span
class="math inline">\(1,594,323 - 16,384 = 1,586,131\)</span>. That’s a
lot.</p>
</div>
<p>Large grammars are undesirable for multiple reasons. They are almost
impossible to decipher for humans. Who is supposed to look at <span
class="math inline">\(16,384\)</span> distinct 13-grams and deduce what
condition they encode? And the larger the grammar, the more
computational resources it consumes. Small grammars are fast and easy to
figure out, large grammars are slow and indecipherable. Small grammars
trump large grammars.</p>
<h2 id="phonological-tiers-allow-for-smaller-grammars">Phonological
tiers allow for smaller grammars</h2>
<p>If you have some background in phonology, you might already be
thinking that there is a much simpler solution: project a
<strong>tier</strong> that contains only sibilants (<em>s</em> and
<em>ʃ</em>), and regulate the shape of this sibilant tier with a
negative bigram grammar containing only <em>sʃ</em> and <em>ʃs</em>.
That’s one darn small grammar.</p>
<div class="example">
<p>The sibilant tier of <em>hasxintilawas</em> is <em>ss</em>, which is
allowed by the negative grammar. The illicit <em>hasxintilawaʃ</em>, on
the other hand, has the sibilant tier <em>sʃ</em>, which is not
allowed.</p>
</div>
<p><img src="tier_good.svg" alt="tier_good.svg" /></p>
<p><img src="tier_bad.svg" alt="tier_bad.svg" /></p>
<div class="exercise">
<p>Carry out the same calculations for</p>
<ul>
<li><em>haʃxintilawaʃ</em>,</li>
<li><em>haʃxinitilawas</em>, and</li>
<li><em>ʃtajanowonowaʃ</em>.</li>
</ul>
</div>
<div class="exercise">
<p>As an abstract example, suppose that our alphabet consists of <span
class="math inline">\(a\)</span>, <span
class="math inline">\(b\)</span>, and <span
class="math inline">\(c\)</span>, and that all symbols except <span
class="math inline">\(c\)</span> should be projected on the tier. What
is the tier of <span
class="math inline">\(\mathit{aabaccacb}\)</span>?</p>
</div>
<p>Tiers are a nice linguistic metaphor, but what is going on here at a
formal level? Exactly the same thing as with stop word removal. We have
a function that removes all irrelevant elements, and then we apply a
specific procedure to the output of this function. For stop word
removal, that follow-up procedure was the construction of a bag of
words. With tier projection, we instead test the output for
well-formedness with respect to an <span
class="math inline">\(n\)</span>-gram grammar.</p>
<h2 id="the-mathematics-of-tiers">The mathematics of tiers</h2>
<p>Remember that <span class="math inline">\(\mathit{del}_S\)</span> is
a function that takes a string as its input and deletes all symbols that
belong <span class="math inline">\(S\)</span>. Tier projection works
pretty much the same, except that one usually specifies which symbols to
keep rather than which to delete. So given a set <span
class="math inline">\(T\)</span> of tier symbols, <span
class="math inline">\(\mathit{del}_T\)</span> takes a string as its
input and keeps only those symbols that belong to <span
class="math inline">\(T\)</span>. This difference is very similar to the
split between positive and negative grammars: <span
class="math inline">\(T\)</span> specifies what may be kept, <span
class="math inline">\(S\)</span> what must not be kept. We can unify
stop word removal and tier projection to a single function <span
class="math inline">\(\mathit{del}_X\)</span>, where <span
class="math inline">\(X\)</span> is some set with a specified polarity.
With <span class="math inline">\(\mathit{del}_{^+X}\)</span>, only the
symbols in <span class="math inline">\(X\)</span> are kept, whereas
<span class="math inline">\(\mathit{del}_{^-X}\)</span> removes all
symbols that belong to <span class="math inline">\(X\)</span> (and only
those).</p>
<div class="exercise">
<p>Compute the values for all of the following:</p>
<ul>
<li><span class="math inline">\(\mathit{del}_{^-\left \{ a,b \right
\}}(\mathit{aaccbad})\)</span></li>
<li><span class="math inline">\(\mathit{del}_{^+\left \{ a,b \right
\}}(\mathit{aaccbad})\)</span></li>
<li><span class="math inline">\(\mathit{del}_{^+\left \{ a,b \right
\}}(\mathit{aababad})\)</span></li>
<li><span class="math inline">\(\mathit{del}_{^-\left \{ a,b \right
\}}(\mathit{aababad})\)</span></li>
<li><span class="math inline">\(\mathit{del}_{^-\left \{ a,b \right
\}}(\varepsilon)\)</span></li>
<li><span class="math inline">\(\mathit{del}_{^+\left \{ a,b \right
\}}(\varepsilon)\)</span></li>
</ul>
</div>
<p>You might think that this isn’t a true unification, we have just
moved the difference between stop word removal and tier projection into
the polarity distinction. But just as with <span
class="math inline">\(n\)</span>-gram grammars, polarity doesn’t
actually matter. For every set <span class="math inline">\(A\)</span> of
symbols drawn from some fixed alphabet <span
class="math inline">\(\Sigma\)</span>, there is some set <span
class="math inline">\(B\)</span> such that <span
class="math inline">\(\mathit{del}_{^-A}(s) =
\mathit{del}_{^+B}(s)\)</span> and <span
class="math inline">\(\mathit{del}_{^+A}(s) =
\mathit{del}_{^-B}\)</span> for every string <span
class="math inline">\(s\)</span> over <span
class="math inline">\(\Sigma\)</span>.</p>
<div class="exercise">
<p>Explain why this holds. Illustrate your argument with a few
examples.</p>
</div>
<p>This is a pretty nifty result. Intuitively, stop word removal and
tier projection seem completely unrelated. One is about cleaning up data
for practical applications, the other about simplifying linguistic
analysis. But mathematically, they are exactly the same thing. In later
units, we will see many more examples of this unifying power of
math.</p>
<div class="exercise">
<p>The term <strong>culminativity</strong> refers to the property that
every word has exactly one primary stress. Suppose that our alphabet is
<span class="math inline">\(\left \{ \sigma, \acute{\sigma} \right
\}\)</span>, where <span class="math inline">\(\sigma\)</span> denotes
an unstressed syllable and <span
class="math inline">\(\acute{\sigma}\)</span> one with primary stress.
Specify a set <span class="math inline">\(^+T\)</span> of tier symbols
and a bigram grammar <span class="math inline">\(G\)</span> to capture
culminativity (<em>hint</em>: ⋊ and ⋉ can be used with tiers, too).</p>
</div>
<h2 id="recap">Recap</h2>
<ul>
<li>No <span class="math inline">\(n\)</span>-gram grammar provides an
elegant account of long-distance phenomena.</li>
<li>The larger the <span class="math inline">\(n\)</span>-grams, the
larger the grammar; large grammars are unwieldy and computationally
inefficient.</li>
<li>Phonological tiers allow for more compact grammars by filtering out
irrelevant material.</li>
<li>The stop word removal function <span
class="math inline">\(\mathit{del}\)</span> is also the function for
constructing phonological tiers.</li>
<li>Math allows us to unify things that look very different at the
surface. In particular, linguistic theory and language technology seem
like very different beasts, but they actually share a lot of math.</li>
</ul>
</div>
</div>
</body>
</html>
