<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Succinctness and choosing between grammars</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <link rel="stylesheet" href="/main/style.css" />
  <!-- Include this in HTML headers to configure and activate MathJax. -->
  <script>
  MathJax = {
      loader: {
          load: ['a11y/assistive-mml']
      },
      options: {
          enableMenu: true,          // set to false to disable the menu
          menuOptions: {
              settings: {
                  assistiveMml: true,   // true to enable assitive MathML
              }
          }
      }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
  -- Do not show solutions
  function Div(elem)
    cls = elem.classes[1]
    if cls == "solution" then
      return {}
    else
      return elem
    end
  end

</head>
<body>
<div class="container with-sidebar">
<div class="sidenav">
<nav id="TOC" role="doc-toc">
<p><a id="site-title" href="/main">Language, Math, and Computation</a></p>
<ul>
<li><a href="#succinctness-and-choosing-between-grammars">Succinctness
and choosing between grammars</a>
<ul>
<li><a href="#differences-in-grammar-size">Differences in grammar
size</a></li>
<li><a href="#upper-bounds-and-rates-of-growth">Upper bounds and rates
of growth</a></li>
<li><a href="#recap">Recap</a></li>
</ul></li>
</ul>
</nav>
</div>
<div class="content">
<h1 id="succinctness-and-choosing-between-grammars">Succinctness and
choosing between grammars</h1>
<div class="prereqs">
<ul>
<li>functions (basics, function growth)</li>
</ul>
</div>
<p>Thanks to all the math we have put to good use, we now have three
expressively equivalent models of phonotactics:</p>
<ol type="1">
<li>strict negative <span class="math inline">\(n\)</span>-gram
grammars, and</li>
<li>mixed negative <span class="math inline">\(n\)</span>-gram grammars,
and</li>
<li>strict positive <span class="math inline">\(n\)</span>-gram
grammars.</li>
</ol>
<p>By “expressively equivalent” we mean that every string language that
can be generated by a grammar of one of those tree types can also be
generated by grammars of the other two types. In fact, we can
automatically translate between these three grammar types as we see
fit.</p>
<p>But this also means that we cannot distinguish between these three
types of grammars based purely on typological data. There is no
phonotactic phenomenon that allows us to advocate conclusively for, say,
strict negative <span class="math inline">\(n\)</span>-gram grammars and
against the other two types. However, we should not conflate expressive
equivalence with total equivalence. These three grammar types can still
differ in other respects, and one of them is succinctness: how many
<span class="math inline">\(n\)</span>-grams does the grammar need to
capture a given phenomenon?</p>
<h2 id="differences-in-grammar-size">Differences in grammar size</h2>
<p>The three grammar types above vary hugely in how compactly they can
model specific phenomena. You already saw a glimpse of this in earlier
exercises, but the true extent only becomes evident once we consider a
few artificial examples.</p>
<div class="example">
<p>Suppose our alphabet contains the symbols <em>a</em>, <em>b</em>,
<em>c</em>, <em>d</em> (and nothing else). Now consider the language
<span class="math inline">\(L\)</span> that contains <em>ab</em>,
<em>aab</em>, <em>aaab</em>, and so on (more succinctly, we can write
<span class="math inline">\(L\)</span> as <em>a<sup>+</sup>b</em>). This
is very easy to express as a positive grammar:</p>
<ol type="1">
<li>⋊a</li>
<li>aa</li>
<li>ab</li>
<li>b⋉</li>
</ol>
<p>The smallest mixed negative grammar for this language isn’t much
bigger:</p>
<ol type="1">
<li>c</li>
<li>d</li>
<li>⋊⋉</li>
<li>⋊b</li>
<li>ba</li>
<li>bb</li>
<li>a⋉</li>
</ol>
<p>The strict negative grammar is twice the size by comparison, making
it hard to decipher what pattern it is supposed to capture:</p>
<ol type="1">
<li>⋊⋉</li>
<li>⋊b</li>
<li>⋊c</li>
<li>⋊d</li>
<li>ac</li>
<li>ad</li>
<li>ba</li>
<li>bb</li>
<li>bc</li>
<li>bd</li>
<li>a⋉</li>
<li>b⋉</li>
<li>c⋉</li>
</ol>
</div>
<div class="example">
<p>Suppose that our alphabet still contains only <em>a</em>, <em>b</em>,
<em>c</em>, <em>d</em>, but <span class="math inline">\(L\)</span> now
follows a more general pattern: 1 or more instances of <em>a</em>,
followed by exactly one instance of <em>b</em> or <em>c</em> or
<em>d</em>. Hence <span class="math inline">\(L\)</span> contains
<em>ab</em>, <em>ac</em>, <em>ad</em>, <em>aab</em>, <em>aac</em>,
<em>aad</em>, <em>aaab</em>, <em>aaac</em>, <em>aaad</em>, and so
on.</p>
<p>The positive grammar is still fairly small.</p>
<ol type="1">
<li>⋊a</li>
<li>aa</li>
<li>ab</li>
<li>ac</li>
<li>ad</li>
<li>b⋉</li>
<li>c⋉</li>
<li>d⋉</li>
</ol>
<p>The mixed negative grammar grows a lot in size:</p>
<ol type="1">
<li>⋊⋉</li>
<li>⋊b</li>
<li>⋊c</li>
<li>⋊d</li>
<li>ba</li>
<li>bb</li>
<li>bc</li>
<li>bd</li>
<li>ca</li>
<li>cb</li>
<li>cc</li>
<li>cd</li>
<li>da</li>
<li>db</li>
<li>dc</li>
<li>dd</li>
<li>a⋉</li>
</ol>
<p>In fact, this also happens to be the strict negative grammar. For
<span class="math inline">\(L\)</span>, allowing <span
class="math inline">\(n\)</span>-grams of variable length does not help
at all.</p>
</div>
<div class="example">
<p>Now suppose our alphabet is <span class="math inline">\(\left \{ a
\right \}\)</span> and consider the language <span
class="math inline">\(L\)</span> that contains all strings over
<em>a</em> whose length is at least 2 (i.e. <em>aa</em>, <em>aaa</em>,
and so on). The mixed negative grammar is incredibly small:</p>
<ol type="1">
<li>⋊⋉</li>
<li>⋊a⋉</li>
</ol>
<p>The strict negative grammar looks slightly different, but has the
same size.</p>
<ol type="1">
<li>⋊⋊⋉</li>
<li>⋊a⋉</li>
</ol>
<p>This time the positive grammar is the largest:</p>
<ol type="1">
<li>⋊⋊a</li>
<li>⋊aa</li>
<li>aaa</li>
<li>aa⋉</li>
<li>a⋉⋉</li>
</ol>
</div>
<div class="example">
<p>Finally, assume that the alphabet <span
class="math inline">\(\Sigma\)</span> is <span
class="math inline">\(\left \{ a,b,c,d,e,f \right \}\)</span> and that
<span class="math inline">\(L\)</span> contains all strings over this
alphabet except that no string may have 5 or more instances of
<em>a</em> in a row. For instance, <em>baaaab</em> and
<em>caaadaaaf</em> are well-formed, but not <em>baaaaab</em> or
<em>ffaaaaaaacabec</em>. The negative grammar for this is maximally
simple:</p>
<ol type="1">
<li>aaaaa</li>
</ol>
<p>The positive grammar, on the other hand, is enormous. It contains all
<span class="math inline">\(n\)</span>-grams in <span
class="math inline">\(\Sigma_E^5\)</span> except <em>aaaaa</em>. That’s
<span class="math inline">\(32,767\)</span> <span
class="math inline">\(n\)</span>-grams: since there are 6 symbols in
<span class="math inline">\(\Sigma\)</span> and 2 edge markers, <span
class="math inline">\(\Sigma_E^5\)</span> contains <span
class="math inline">\((6+2)^5 = 8^5 = 32,768\)</span> 5-grams.</p>
</div>
<p>Overall, there doesn’t seem to be much regularity. Sometimes a
positive grammar is smaller, sometimes a negative one, and sometimes it
matters whether the negative grammar is strict or mixed while in other
cases the two look exactly the same. Sometimes the differences is only
one or two <span class="math inline">\(n\)</span>-grams, sometimes it’s
tens of thousands. So is this a case of anything goes where one can
never be quite sure how things will pan out? No, quite to the
contrary.</p>
<h2 id="upper-bounds-and-rates-of-growth">Upper bounds and rates of
growth</h2>
<p>Even though it is difficult to tell how things may pan out for a
specific phenomenon or string language, that does not mean that there
are no regularities. It’s just that these regularities are a bit more
abstract in nature as they take the form of <strong>upper
bounds</strong>. Since every strict grammar, whether positive or
negative, is built from members of <span
class="math inline">\(\Sigma_E^n\)</span> for some alphabet <span
class="math inline">\(\Sigma\)</span> and some choice of <span
class="math inline">\(n\)</span>, its size cannot exceed that of <span
class="math inline">\(\Sigma_E^n\)</span>. And that size is easy to
calculate. Each <span class="math inline">\(n\)</span>-gram furnishes
<span class="math inline">\(n\)</span> positions, each one of which must
be a symbol from <span class="math inline">\(\Sigma\)</span> or one of
the two edge markers. So if <span class="math inline">\(\Sigma\)</span>
contains <span class="math inline">\(m\)</span> symbols, there are <span
class="math inline">\(m+2\)</span> choices for each position, and since
there are <span class="math inline">\(n\)</span> positions, this means
there are <span class="math inline">\((m+2)^n\)</span> different
combinations. Hence the size of <span
class="math inline">\(\Sigma_E^n\)</span> is <span
class="math inline">\((m+2)^n\)</span>, and that’s a fixed upper bound
on the size of any <span class="math inline">\(n\)</span>-gram grammar
over <span class="math inline">\(\Sigma\)</span>.</p>
<div class="example">
<p>Suppose <span class="math inline">\(\Sigma \mathrel{\mathop:}=\left
\{ a,b \right \}\)</span>. Then <span
class="math inline">\(\Sigma_E^2\)</span> has <span
class="math inline">\((2+2)^2 = 4^2 = 16\)</span> members. We can list
them all:</p>
<ol type="1">
<li>⋊⋊</li>
<li>⋊⋉</li>
<li>⋊a</li>
<li>⋊b</li>
<li>a⋊</li>
<li>a⋉</li>
<li>aa</li>
<li>ab</li>
<li>b⋊</li>
<li>b⋉</li>
<li>ba</li>
<li>bb</li>
<li>⋉⋊</li>
<li>⋉⋉</li>
<li>⋉a</li>
<li>⋉b</li>
</ol>
</div>
<div class="exercise">
<p>For <span class="math inline">\(n \geq 2\)</span>, no grammar ever
needs to contain every member of <span
class="math inline">\(\Sigma_E^n\)</span>. Explain why.</p>
</div>
<p>This insight provides us with a fixed upper bound for any given
choice of <span class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(n\)</span> such that no grammar can be bigger than
that. But that by itself isn’t really that interesting, we want to know
how that upper bound changes as we vary <span
class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(n\)</span>. We can make this more visual by
drawing a table, where rows indicate the size of the alphabet (plus both
edge markers) and columns indicate the length of the <span
class="math inline">\(n\)</span>-grams. Each cell tells us how many
<span class="math inline">\(n\)</span>-grams there are for that specific
combination of those two values.</p>
<table style="width:100%;">
<colgroup>
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
<col style="width: 16%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"></th>
<th style="text-align: right;">1</th>
<th style="text-align: right;">2</th>
<th style="text-align: right;">3</th>
<th style="text-align: right;">4</th>
<th style="text-align: right;">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;"><strong>3</strong></td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">27</td>
<td style="text-align: right;">81</td>
<td style="text-align: right;">243</td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>4</strong></td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">64</td>
<td style="text-align: right;">256</td>
<td style="text-align: right;">1024</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>5</strong></td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">125</td>
<td style="text-align: right;">625</td>
<td style="text-align: right;">3125</td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>6</strong></td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">36</td>
<td style="text-align: right;">216</td>
<td style="text-align: right;">1296</td>
<td style="text-align: right;">7776</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>7</strong></td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">49</td>
<td style="text-align: right;">343</td>
<td style="text-align: right;">2401</td>
<td style="text-align: right;">16807</td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>8</strong></td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">64</td>
<td style="text-align: right;">512</td>
<td style="text-align: right;">4096</td>
<td style="text-align: right;">32768</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>9</strong></td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">81</td>
<td style="text-align: right;">729</td>
<td style="text-align: right;">6561</td>
<td style="text-align: right;">59049</td>
</tr>
<tr class="even">
<td style="text-align: right;"><strong>10</strong></td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">1,000</td>
<td style="text-align: right;">10,0000</td>
<td style="text-align: right;">100,000</td>
</tr>
<tr class="odd">
<td style="text-align: right;"><strong>100</strong></td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">10,000</td>
<td style="text-align: right;">1,000,000</td>
<td style="text-align: right;">100,000,000</td>
<td style="text-align: right;">10,000,000,000</td>
</tr>
</tbody>
</table>
<p>As you can see, the numbers grow quite a bit from the top to the
bottom, but much faster from left to right. In other words, <span
class="math inline">\(n\)</span> plays a much bigger role in determining
the size of <span class="math inline">\(\Sigma_E^n\)</span>. The number
of bigrams over an alphabet with 100 symbols (including edge markers) is
10,000, which is still smaller than the number of 5-grams over an
alphabet with 7 symbols (i.e. 16,807). Our upper bound grows
<strong>exponentially</strong> with <span
class="math inline">\(n\)</span>, but only <strong>polynomially</strong>
with <span class="math inline">\(\Sigma\)</span>.</p>
<p>What does this tell us? While we can freely choose between strict
negative grammars, mixed negative grammars, and (strict) positive
grammars because they are interchangeable, grammar size can vary a lot
depending on the phenomenon. This does not matter too much as long as
<span class="math inline">\(\Sigma\)</span> and <span
class="math inline">\(n\)</span> are both small, but as we increase the
size of the alphabet and the length of the <span
class="math inline">\(n\)</span>-grams, it becomes more noticeable. In
fact, we do not even need to worry too much about <span
class="math inline">\(\Sigma\)</span> as <span
class="math inline">\(n\)</span> has a much bigger impact on this. Even
with very small alphabets, <span
class="math inline">\(\Sigma_E^n\)</span> is giant for <span
class="math inline">\(n &gt; 5\)</span>.</p>
<div class="example">
<p>For an alphabet with just two symbols, <span
class="math inline">\(\Sigma_E^6\)</span> is 4,096, and <span
class="math inline">\(\Sigma_E^{10}\)</span> is 1,048,576. That’s more
than the number of trigrams over an alphabet with close to 100
symbols.</p>
</div>
<div class="exercise">
<p>Calculate the number of 100-grams over an alphabet with 3 symbols
(including edge markers) and compare it to the number of trigrams over
an alphabet with 100 symbols.</p>
</div>
<div class="example">
<p>The age of the universe is estimated to be around <span
class="math inline">\(436, 000, 000, 000, 000, 000\)</span> seconds.
That’s 436 quadrillion seconds, which one can also write mathematically
as <span class="math inline">\(4.36 \times 10^{17}\)</span>. This means
that given an alphabet with 8 symbols plus 2 edge markers, the set of
all 18-grams already exceeds the number of seconds since the Big Bang.
And it doesn’t do that by just a slim margin. If, starting from the
birth of the universe, you had been listing all 18-grams over that
alphabet with edge markers, uttering two 18-grams per second, you still
wouldn’t be done for another 128 quadrillion seconds, which is 4 billion
years (I’ve rounded this a bit for your convenience). Needless to say,
we should be skeptical if our investigation ever leads us to conclude
that natural languages use <span class="math inline">\(n\)</span>-grams
with a large value for <span class="math inline">\(n\)</span>.</p>
</div>
<div class="exercise">
<p>Natural languages tend to use much more than just 8 distinct sounds.
In fact, some languages have been argued to use close to a 100 distinct
sounds. Calculate the smallest value of <span
class="math inline">\(n\)</span> for which the number of <span
class="math inline">\(n\)</span>-grams over an alphabet with 100 symbols
(including edge markers) exceeds the number of seconds since the Big
Bang.</p>
</div>
<div class="exercise">
<p>One can also use <span class="math inline">\(n\)</span>-grams to
model certain aspects of sentences, which each word corresponding to a
position of the <span class="math inline">\(n\)</span>-gram. For
example, <em>John likes</em> would be a bigram and <em>bought these
truffles</em> would be a trigram. Native speakers of English know at
least 10,000 distinct words, and that’s if we count distinct surface
forms such as <em>buy</em> and <em>buys</em> as a single word. Without
that distinction, a native speaker’s vocabulary can quickly reach six
digit territory.</p>
<p>Given an alphabet with 10,000 distinct symbols (including edge
markers), what is the smallest value of <span
class="math inline">\(n\)</span> such that the number of <span
class="math inline">\(n\)</span>-grams is greater than the age of the
universe in seconds?</p>
</div>
<p>So what are we to infer from all these calculations? First and
foremost, scaling up the size of <span
class="math inline">\(n\)</span>-grams isn’t a very appealing strategy.
Since grammar size grows exponentially with <span
class="math inline">\(n\)</span>, even small increases of <span
class="math inline">\(n\)</span> have a huge impact on grammar size.
Ideally, we keep <span class="math inline">\(n\)</span> limited to 2 or
3. At no point should we go beyond 5 as this is where the combinatorial
explosion quickly becomes unmanageable. Yes, we can mitigate some of the
blow-up by carefully switching between strict positive, strict negative,
and mixed negative grammars, but that can only do so much. The good news
is that it is very rare for a phenomenon to require more than 5-grams.
Such phenomena do exist, but as we will see next, they can actually be
given a very compact and intuitively pleasing account in terms of
bigrams if we make a small change to our formalism.</p>
<h2 id="recap">Recap</h2>
<ul>
<li>Depending on the phenomenon at hand, a positive or a negative
grammar may be more succinct.</li>
<li>The difference in grammar size may not always be very pronounced,
but it can be.</li>
<li>The difference cannot exceed the size of <span
class="math inline">\(\Sigma_E^n\)</span>, which grows polynomially with
<span class="math inline">\(\Sigma\)</span> and exponentially with <span
class="math inline">\(n\)</span>.</li>
<li>If your analysis requires you to move beyond 5-grams, you are better
off exploring other formalisms or analyses.</li>
</ul>
</div>
</div>
</body>
</html>
